{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Reshape, Merge,Activation, Conv2D, Flatten,Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Activation, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução a YOLO ###\n",
    "\n",
    "[Redes Neurais Convolucionais](http://cs231n.github.io/convolutional-networks/) (CNNs) tem sido utilizadas em diversas aplicações, sendo bastante populares para aplicações voltadas a imagens e atingindo um alto índice de acurácia. Entretanto, em algumas situações, é necessário reconhecer objetos na imagem e localizá-los com uma performance quase ou melhor que a humana.\n",
    "\n",
    "Existem algumas abordagens que utilizam CNNs também para detecção, como [R-CNNs](https://arxiv.org/abs/1506.01497) que são consideravelmente custosas e um pouco lentas devido a utilização de diferentes pipelines para classificação e geração de bouding boxes. A YOLO realiza essas etapas simultaneamente, retornando uma melhor performance em tempo real. Atualmente, existem duas versões da YOLO, onde a primeira diferença entre elas é a arquitetura da Rede Neural utilizada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Arquitetura YOLOv1](https://pjreddie.com/media/files/papers/yolo.pdf)\n",
    "\n",
    "No primeiro modelo da YOLO, a rede neural criada foi inspirada na [GoogleLeNet](https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf), rede neural utilizada para classificação de imagens com menor taxa de erro no desafio ImageNet de 2014 (6.7% de erro).\n",
    "\n",
    "Neste modelo, existem 24 camadas convolucionais para extração de características, enquanto as duas últimas camadas da rede são completamente conectadas para identificar o objeto e suas coordenadas, conforme Figura abaixo.\n",
    "\n",
    "![alt text](../imgs/yolo_architecture.png \"Title\")\n",
    "\n",
    "Na figura, percebe-se que as camadas convolucionais são divididas em 6 blocos principais, sendo os dois primeiros formados apenas por uma camada convolucional e max-pooling para extração das características primárias. Apesar do uso da técnica max-pooling reduzir consideravelmente a dimensão da imagem (widthxheight), a profundidade, obtida pela quantidade de filtros aplicados a cada camada, permanece constante. \n",
    "\n",
    "Dessa forma, para arquiteturas complexas como a YOLO, a utilização de muitas camadas convolucionais com um número de filtros elevado resulta em um custo computacional muito alto. Uma forma de evitar isso e reduzir a largura da saída de cada camada é aplicar camadas convolutivas de dimensões 1x1xn, um conceito abordado em [Network in Network](https://arxiv.org/abs/1312.4400). Ao utilizar essas dimensões, o número de entradas (neurônios) da próxima camada reduz em um fator dado pela equação abaixo:\n",
    "\n",
    "$$\\frac{quantidade-de-filtros-da-camada-atual}{quantidade-de-filtros-da-camada-convolutiva-1x1}$$\n",
    "\n",
    "Assim, a partir do terceiro bloco da rede, uma camada convolucional 1x1 é aplicada antes da aplicação de uma camada 3x3. Além disso, a quantidade de filtros dobra a cada camada, iniciando com 124 filtros e encerrando com 1024. Esse aumento de filtros foi inspirado no modelo de rede [VGG](https://arxiv.org/abs/1409.1556), tida como uma das redes mais utilizadas como base de detecção.\n",
    "\n",
    "Esse processo repete-se até a vigésima camada, uma vez que essas são as camadas responsáveis pela extração de características e reconhecimento da imagem. O modelo é então pré-treinado utilizando estas camadas, para, em seguida, ser utilizado para detecção. Para isso, as últimas duas camadas convolucionais foram adicionadas, assim como as camadas completamente conectadas.\n",
    "\n",
    "Por fim, para realizar detecção utilizando essa arquitetura, quatro camadas convolucionais e duas camadas completamente conectadas são adicionadas. Entretanto, o artigo da YOLO não descreve os hiper-parâmetros destas camadas, de forma que a implementação da yolo neste notebook não utilizou as mesmas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo(input_image):\n",
    "    \"\"\"\n",
    "    Implementação da arquitetura da YOLO dividida nos seis blocos convolucionais e nas camadas\n",
    "    completamente conectadas.\n",
    "    Parâmetro: dimensão da imagem\n",
    "    Retorna: modelo final implementado\n",
    "    \"\"\"    \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Bloco 1 - Uma camada convolucional não muito densa (64 filtros)\n",
    "    model.add(Conv2D(64, (7,7), strides=(2,2), padding='same', name='conv_1',input_shape=(416, 416, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Bloco 2 \n",
    "    model.add(Conv2D(192, (3,3), strides=(2,2), padding='same', name='conv_2'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    #Bloco 3 - Transição entre dimensões 256 e 512 a partir da utilização de camadas\n",
    "    #convolucionais 1x1\n",
    "    model.add(Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_3'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_4'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_5'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_6'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    #Bloco 4  - Transição entre dimensões 512 e 1024 a partir de camadas convolucionais\n",
    "    # 1x1\n",
    "    model.add(Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_7'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_8'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_9'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_10'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_11'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_12'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_13'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_14'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    \n",
    "    #Bloco 5 - Transição entre dimensões 512 e 1024 a partir de camadas convolucionais\n",
    "    # 1x1\n",
    "    model.add(Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_19'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20'))\n",
    "    model.add(LeakyReLU(alpha=0.1))  \n",
    "    model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_21'))\n",
    "    model.add(LeakyReLU(alpha=0.1)) \n",
    "    model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22'))\n",
    "    model.add(LeakyReLU(alpha=0.1)) \n",
    "    \n",
    "    #Bloco 6\n",
    "    model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_23'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_24'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Arquitetura YOLO9000](https://arxiv.org/pdf/1612.08242.pdf)\n",
    "\n",
    "De forma similar a primeira arquitetura da YOLO, a YOLO9000 possui seis blocos convolucionais principais, sendo utilizados filtros 3x3 para extração das caracteristicas e filtros 1x1 para redução de profundidade em cada camada. Além disso, a quantidade de filtros dobra a cada bloco, iniciando em 32 e obtendo 1024 na última camada, conforme Figura abaixo. \n",
    "![alt text](../imgs/yolov2_architecture.png \"Title\")\n",
    "\n",
    "Entretanto, neste modelo, conhecido como Darknet-19, apenas 19 camadas convolucionais são utilizadas, sendo a última utilizada para identificar o objeto e suas coordenadas, eliminando-se assim a necessidade de utilizar camadas completamente conectadas e resultando em um modelo completamente convolucional. Essa abordagem facilita a predição em diferentes escalas e é também utilizada nos modelos [SSD](https://arxiv.org/pdf/1512.02325.pdf) (Single Shot Detector). Para isso, adiciona-se uma última camada convolucional de dimensões 1x1x1000, onde 1000 é a quantidade de classes existentes no dataset.\n",
    "\n",
    "Além disso, cada camada convolucional é seguida de uma operação de [normalização de batch](https://arxiv.org/abs/1502.03167). Essa técnica é utilizada para normalizar a média e a variância de cada camada da rede, de forma que, ao utilizar uma arquitetura complexa como a YOLO9000 com 19 camadas convolucionais, a distribuição permaneça aproximadamente constante, tornando a rede assim mais estável. Para a YOLO, a utilização dessa abordagem melhora em 2% mAP e elimina a necessidade de utilizar Dropout.    \n",
    "\n",
    "Por fim, essa arquitetura utiliza skip connections, um conceito abordado em [redes residuais](https://arxiv.org/abs/1512.03385), responsável por criar um bloco paralelo na rede. Com isso, uma skip connection é adicionada na camada 13 (última camada com 512 filtros) e depois concatenada com a última camada de 1024 filtros, de forma que a rede considere igualmente as características de resolução alta das últimas camadas e as de baixa resolução das primeiras camadas, melhorando a performance da rede em 1%. \n",
    "\n",
    "Essa última alteração é eficaz na YOLO devido a complexidade do modelo. Considerando que a arquitetura é muito densa, a medida que mais camadas convolucionais são adicionadas, o gradiente pode começar a ter problemas de convergência, aumentando-se assim a taxa de erro. Dessa forma, ao adicionar uma skip connection na metade do modelo (camada 13 de 24), o gradiente retém as informações extraídas das primeiras camadas e evita os problemas de convergência, ao mesmo tempo as características das camadas restantes são extraídas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2(input_image,num_classes):\n",
    "    \"\"\"\n",
    "    Implementação da arquitetura da YOLO dividida nos seis blocos convolucionais e nas camadas\n",
    "    completamente conectadas.\n",
    "    Parâmetro: dimensão da imagem\n",
    "    Retorna: modelo final implementado\n",
    "    \"\"\"   \n",
    "        \n",
    "    # Bloco 1 - Camadas de baixa profundidade (32 filtros)\n",
    "    x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1')(input_image)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Bloco 2 - Camadas de baixa profundidade (64 filtros)\n",
    "    x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2')(x)\n",
    "    x = BatchNormalization(name='norm_2')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Bloco 3 - Transição entre dimensões 64 e 128 a partir de camadas\n",
    "    # convolucionais 1x1\n",
    "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3')(x)\n",
    "    x = BatchNormalization(name='norm_3')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4')(x)\n",
    "    x = BatchNormalization(name='norm_4')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5')(x)\n",
    "    x = BatchNormalization(name='norm_5')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Bloco 4 - Transição entre dimensões 128 e 256 a partir de camadas\n",
    "    # convolucionais 1x1\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6')(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7')(x)\n",
    "    x = BatchNormalization(name='norm_7')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8')(x)\n",
    "    x = BatchNormalization(name='norm_8')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Bloco 5 - Transição entre dimensões 512 e 256 a partir de camadas\n",
    "    # convolucionais 1x1\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9')(x)\n",
    "    x = BatchNormalization(name='norm_9')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10')(x)\n",
    "    x = BatchNormalization(name='norm_10')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11')(x)\n",
    "    x = BatchNormalization(name='norm_11')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12')(x)\n",
    "    x = BatchNormalization(name='norm_12')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13')(x)\n",
    "    x = BatchNormalization(name='norm_13')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    #Adicionar skip connection para bloco residual\n",
    "    skip_connection = x\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Bloco 6 - Transição entre dimensões 512 e 1024 a partir de camadas\n",
    "    # convolucionais 1x1\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_14')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_15')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_16')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_17')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_18')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    #Bloco 7\n",
    "\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_19')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_20')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Bloco Residual - concatenando modelo de rede de baixa resolução das primeiras \n",
    "    #camadas(até 512 filtros) e alta resolução das últimas camadas (1024 filtros)\n",
    "    skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "    skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "    x = concatenate([skip_connection, x])\n",
    "    \n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_22')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    #Última camada para detecção, as dimensões de entrada para essa camada são obtidas\n",
    "    #a partir da equação num_anchor_boxes * (num_classes+5).\n",
    "    x = Conv2D((5*(num_classes+5)), (1,1), strides=(1,1), padding='same', name='conv_23', use_bias=False)(x)\n",
    "    \n",
    "    #Estruturando a saída para ter suporte ao sistema de grids da YOLO que divide a imagem em \n",
    "    #13x13 células.\n",
    "    output = layers.Reshape((13, 13, 5, 4 + 1 + num_classes))(x)\n",
    "         \n",
    "    # small hack to allow true_boxes to be registered when Keras build the model \n",
    "    # for more information: https://github.com/fchollet/keras/issues/2790\n",
    "    true_boxes  = layers.Input(shape=(1, 1, 1, 50, 4))\n",
    "    output = layers.Lambda(lambda args: args[0])([output, true_boxes])\n",
    "    \n",
    "    model = models.Model([input_image, true_boxes], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testar modelos ###\n",
    "yolo_model = yolo2(Input(shape=(416, 416, 3)),100)\n",
    "#yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando modelo no Keras \n",
    "\n",
    "Os modelos implementados neste notebook foram feitos para ilustrar e melhorar o entendimento da arquitetura da YOLO, não sendo utilizados para detecção propriamente dita. \n",
    "\n",
    "Para a detecção, os pesos da rede treinada foram disponibilizados pelos autores da [YOLO](https://pjreddie.com/darknet/yolo/). Dessa forma, para finalizar esse notebook, o método load_model do Keras carrega o modelo da YOLO9000 e será utilizado nos demais notebooks que ilustrarão a implementação do algoritmo de detecção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 608, 608, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 608, 608, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 608, 608, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 608, 608, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 304, 304, 32) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 304, 304, 64) 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 304, 304, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 304, 304, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 152, 152, 64) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 152, 152, 128 73728       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 152, 152, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 152, 152, 64) 8192        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 152, 152, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 152, 152, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 152, 152, 128 73728       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 152, 152, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 76, 76, 128)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 76, 76, 256)  294912      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 76, 76, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 76, 76, 128)  32768       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 76, 76, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 76, 76, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 76, 76, 256)  294912      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 76, 76, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 38, 38, 256)  0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 38, 38, 512)  1179648     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 38, 38, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 38, 38, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 38, 38, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 38, 38, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 38, 38, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 38, 38, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 19, 19, 512)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 19, 19, 1024) 4718592     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 19, 19, 1024) 4096        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 19, 19, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 19, 19, 1024) 4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 19, 19, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 19, 19, 1024) 4096        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 19, 19, 1024) 4096        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 38, 38, 64)   32768       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 38, 38, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 38, 38, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 19, 19, 1024) 4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "space_to_depth_x2 (Lambda)      (None, 19, 19, 256)  0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 19, 19, 1280) 0           space_to_depth_x2[0][0]          \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 19, 19, 1024) 11796480    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 19, 19, 1024) 4096        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 19, 19, 425)  435625      leaky_re_lu_22[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 50,983,561\n",
      "Trainable params: 50,962,889\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(\"../model_data/yolo.h5\")\n",
    "yolo_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
